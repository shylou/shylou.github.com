<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[liushy]]></title>
  <subtitle><![CDATA[I'm waiting for you]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://liushy.com/"/>
  <updated>2017-03-06T12:21:46.344Z</updated>
  <id>http://liushy.com/</id>
  
  <author>
    <name><![CDATA[Liushy]]></name>
    
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[]]></title>
    <link href="http://liushy.com/2017/03/04/iptables-note/"/>
    <id>http://liushy.com/2017/03/04/iptables-note/</id>
    <published>2017-03-04T05:56:58.000Z</published>
    <updated>2017-03-06T12:21:22.000Z</updated>
    <content type="html"><![CDATA[<pre><code><span class="attribute">title</span>: <span class="string">Iptables笔记      </span>
</code></pre><p>tags: [iptables,nat]      </p>
<h2 id="categories:_Linux_">categories: Linux      </h2>
<h2 id="前言">前言</h2>
<p>Linux网络相关的技术有很多，常见的如Iptables，TC(Traffic Control)，Linux Bridge等会经常被应用到生产环境中，特别在组网时，部分技术会成为至关重要的解决方案。之前在读书期间，有做过利用Iptables做防火墙，过滤相关IP数据包，以及利用Iptables结合TC进行数据流的Qos保障和流量控制。都快忘了怎么玩，最近在CI环境中，跑Robot测试用例时，需要外网主机访问云平台的虚机，我采取的方法就是利用Iptables做DNAT转换。所以，学习并熟练运用相关Linux网络技术有助于解决一些网络相关的疑难问题。熟悉这些技术的小伙伴也许会觉得很简单，不过好记性不如烂笔头，本文将记录一下本人学习Iptables的笔记。</p>
<h2 id="四表五链">四表五链</h2>
<p>首先，介绍一下iptables技术中的表和链。iptables有四种表（table）和五条链（chain），其中表是按照对数据包的动作区分的，链是按照不同的Hook点来区分的。其原理是将处理不同IP包（五元组任意组合）的规则写入不同的链当中，数据包进来后，会与这些规则进行匹配，一旦匹配成功，即执行规则中的动作。   </p>
<font color="blue" size="4">#四表</font>    

<p>iptables四种表分别是Filter，NAT，Mangle和Raw。表的处理优先级：raw&gt;mangle&gt;nat&gt;filter。功能介绍如下：  </p>
<ul>
<li>Filter表：进行一般的包过滤操作；</li>
<li>NAT表：进行网络地址转换（IP/端口映射）；</li>
<li>Mangle表：进行数据包的修改，比如tos，ttl这些字段以及打标记（Mark）；</li>
<li>Raw表：此表优先级最高，功能是不再让iptables做数据包的链接跟踪处理，提高性能。<a href="http://blog.chinaunix.net/uid-11639156-id-3181909.html" target="_blank" rel="external">相关资料</a>   </li>
</ul>
<p>前面三个表就能满足处理常见问题的需要，使用<code>[-t table]</code>指定规则表，关于表的内容就不深入的阐述了。 <a href="http://blog.chinaunix.net/uid-134240-id-62371.html" target="_blank" rel="external">参考网站</a>  </p>
<font color="blue" size="4">#五链</font>      

<p>iptables的链规则定义了数据包被处理的位置，linux定义了五条链，我们也可以自定义新的链，借用<a href="http://linux.vbird.org/linux_server/0250simple_firewall.php#netfilter_chain" target="_blank" rel="external">鸟哥</a>的图：  </p>
<p><img src="/img/iptables-chain.JPEG" alt="chain"><br>简单理解，这五条链的规则：   </p>
<ul>
<li>PREROUTING:数据包进入路由表之前；</li>
<li>INPUT:通过路由表后目的地为本机，上送协议栈；</li>
<li>FORWARD:通过路由表后，经由本机转发，不上送协议栈；</li>
<li>OUTPUT:由本机产生，向外转发；</li>
<li>POSTROUTIONG:发送到网卡接口之前。   </li>
</ul>
<p>梳理一下，如果数据包只是通过本机转发而不上送本机处理的，路径：<font color="red"><em>PREROUTING—&gt;FORWARD—&gt;POSTROUTIONG</em></font>；如果是需要本机处理的，路径：<font color="red"><em>PREROUTING—&gt;INPUT—&gt;OUTPUT—&gt;POSTROUTIONG</em></font>。   </p>
<p>iptables表与链的对应关系：<br><img src="/img/table-chain.JPEG" alt="table-chain"> </p>
<p>使用如下命令指定规则链，如<code>[-A chain]</code>：</p>
<blockquote>
<p>-A, —append：   新增规则到某个规则链中，该规则将会成为规则链中的最后一条规则。<br>-D, —delete：    从某个规则链中删除一条规则，可以输入完整规则，或指定规则编号。<br>-R, —replace：    取代现行规则，规则被取代后并不会改变顺序。<br>-I, —insert：    插入一条规则，原本该位置上的规则将会往后移动一个顺位。<br>-L, —list：    列出某规则链中的所有规则。<br>-F, —flush：    删除某规则链中的所有规则。<br>-Z, —zero：   将封包计数器归零。封包计数器是用来计算同一封包出现次数，是过滤阻断式攻击不可或缺的工具。<br>-N, —new-chain：     定义新的规则链。<br>-X, —delete-chain：    删除某个规则链。<br>-P, —policy：     定义过滤政策。 也就是未符合过滤条件之封包，预设的处理方式。<br>-E, —rename-chain：      修改某自定义规则链的名称。</p>
</blockquote>
<h2 id="使用Iptables_">使用<em>Iptables </em></h2>
<p>使用iptables的语法：<br>　　　　　　<br>　　<font color="red" size="4">iptables　[-t table]　command　[chain]　[match]　[-j target/jump]　</font>  </p>
<p>其中，<code>-t table</code>前文提到，是指定表规则，<code>command</code>后面指定链规则；<code>match</code>指定数据包的匹配规则，一般是指定五元组等；<code>-j target/jump</code>指定匹配成功后的动作，主要包括ACCEPT（通过），DROP（丢弃），REJECT（丢弃并重定向），DNAT，SNAT，MARK，MASQUERADE（伪装宿主机IP）。匹配规则的常用语句：   </p>
<blockquote>
<p>-p, —protocol：匹配通讯协议类型是否相符。<br>-s, —src, —source： 匹配封包的来源 IP，可以匹配单机或网络。<br>-d, —dst, —destination：匹配封包的目的地 IP。<br>-i, —in-interface： 匹配封包是从哪块网卡进入，可以使用通配字符 + 来做大范围匹配。<br>-o, —out-interface：匹配封包要从哪 块网卡送出。<br>—sport, —source-port：匹配封包的源端口，可以匹配单一端口，或是一个范围。<br>—dport, —destination-port：匹配封包的目的地端口号。<br>—tcp-flags：TCP 封包的状态标志。<br>-m limit —limit：匹配某段时间内封包的平均流量。<br>—limit-burst：匹配瞬间大量封包的数量，超过此上限的封包将被直接丢弃。<br>-m mac —mac-source ：匹配封包来源网络接口的硬件地址，这个参数不能用在 OUTPUT 和 POSTROUTING 规则链上。<br>—mark：匹配封包是否被表示某个号码。   </p>
</blockquote>
<p>配置iptables后，可以使用如下命令查看规则及其对应的编号：   </p>
<p>　　<font color="red" size="4">iptables　-L　-n　—line-number</font>   </p>
<p>接下来举几个例子。</p>
<p><font color="blue" size="4">#包过滤</font><br>包过滤也就是实现简单的防火墙功能，阻止或者允许指定包的通过。例如：<br>允许访问本机的ICMP包，丢弃经过本机转发的http（80端口）包： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">iptables　-A　INPUT　-p　icmp　-j　ACCEPT     </div><div class="line">iptables　-A　FORWARD　-p　tcp　--dport　<span class="number">80</span>　-j　DROP</div></pre></td></tr></table></figure>


<p>其中，<code>-p</code>指定了协议，如<code>-p　icmp</code>指定了ICMP协议，<code>-p　tcp　--dport　80</code>指定了TCP协议，以及目的端口为80即http协议常用的tcp端口。</p>
<p><font color="blue" size="4">#内外网访问</font><br>内外网访问，就需要为内网的虚机分配一个外网地址。这里两个概念需要简单介绍一下，那就是DNAT(目的IP网络地址转换)和SNAT(源IP网络地址转换)。两者的应用场景是，当外网访问内网服务器时，要对目的IP进行DNAT转换；而当内网主机要访问外网时，需进行SNAT转换。例如：  </p>
<p>场景一：</p>
<ul>
<li>eth0:10 172.168.0.110（外网IP）   </li>
<li>eth1:10.0.2.1（内网IP）     </li>
<li>内网虚机1：10.0.2.5 。外网主机能够访问该虚机，做一对一的DNAT转换： </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ifconfig etho:<span class="number">10</span> <span class="number">172.168</span>.<span class="number">0.110</span>/<span class="number">24</span> up</div><div class="line">iptables -t nat -A PREROUTING <span class="operator">-d</span> <span class="number">172.168</span>.<span class="number">0.110</span> -j DNAT -to--destination <span class="number">10.0</span>.<span class="number">2.5</span>  </div><div class="line">iptables -t nat -A PREROUTING <span class="operator">-d</span> <span class="number">10.0</span>.<span class="number">2.5</span> -j SNAT -to--source <span class="number">10.0</span>.<span class="number">2.1</span></div></pre></td></tr></table></figure>


<p>以上命令可以理解为：</p>
<ul>
<li>将目的地址是172.168.0.110的数据包的目的地址修改为10.0.2.5</li>
<li>将目的地址为10.0.2.5的数据包的源地址修改为10.0.2.1    </li>
</ul>
<p>所以外网主机访问内网虚机1，不是虚机的IP地址，而是虚机进行DNAT的外网地址，当数据包到达linux服务器，首先会将数据包的目的地址改为虚机地址并进行转发；而这时iptables还会将目的地址是虚机地址的数据包进行SNAT转换，将源地址改为虚机能通信的地址10.0.2.1，这就保证了虚机能够回复外网的数据包。   </p>
<p>场景二：   </p>
<ul>
<li>eth0:10 172.168.0.110（外网IP）   </li>
<li>eth1:10.0.2.1（内网IP）     </li>
<li>内网虚机1：10.0.2.5 </li>
<li>内网虚机2：10.0.2.6。外网主机能够访问两台虚机的http服务（80端口）：    </li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ifconfig etho:<span class="number">10</span> <span class="number">172.168</span>.<span class="number">0.110</span>/<span class="number">24</span> up</div><div class="line">iptables -t nat -A PREROUTING <span class="operator">-d</span> <span class="number">172.168</span>.<span class="number">0.110</span> -p tcp --dport <span class="number">80</span> -j DNAT -to--destination <span class="number">10.0</span>.<span class="number">2.5</span>:<span class="number">80</span></div><div class="line">iptables -t nat -A POSTROUTING <span class="operator">-d</span> <span class="number">10.0</span>.<span class="number">2.5</span> -j SNAT -to--source <span class="number">10.0</span>.<span class="number">2.1</span>  </div><div class="line">iptables -t nat -A PREROUTING <span class="operator">-d</span> <span class="number">172.168</span>.<span class="number">0.110</span> -p tcp --dport <span class="number">81</span> -j DNAT -to--destination <span class="number">10.0</span>.<span class="number">2.6</span>:<span class="number">80</span> </div><div class="line">iptables -t nat -A POSTROUTING <span class="operator">-d</span> <span class="number">10.0</span>.<span class="number">2.6</span> -j SNAT -to--source <span class="number">10.0</span>.<span class="number">2.1</span></div></pre></td></tr></table></figure>


<p>上面的命令，我让两台虚机公用一个外网地址的不同端口号，简单的做了一个端口映射。外网主机可以通过172.168.0.110的80和81端口分别访问内网虚机1和2的http服务。</p>
<h2 id="总结">总结</h2>
<p>目前的云平台如OpenStack，其网络管理项目Neutron对租户的安全组也是基于Iptables来做的。前两天某云的租户互通事件，引起很大的讨论，可见云网络中安全问题越来受到重视。所以，熟练使用Iptables，也许会帮助你管理好自己的云网络。写的有点零碎，但尽量争取不了解的人一看就会用，自己回头看能很快明白，后续可能还会在此基础上进行补充，就这些吧。    </p>
<p><strong>个人分析，欢迎指正，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<pre><code><span class="attribute">title</span>: <span class="string">Iptables笔记      </span>
</code></pre><p>tags: [iptables,nat]      </p>]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[解析Floodlight之Forwarding模块]]></title>
    <link href="http://liushy.com/2017/02/12/floodlight-forwarding/"/>
    <id>http://liushy.com/2017/02/12/floodlight-forwarding/</id>
    <published>2017-02-12T07:07:13.000Z</published>
    <updated>2017-02-12T08:20:46.000Z</updated>
    <content type="html"><![CDATA[<p>Floodlight的流表下发模块是Forwarding类。处理Packet-in消息的方法是<code>processPacketInMessage()</code>，该方法根据决策(Decision)或者包的类型决定对Packet-in消息执行动作，对于广播包(BroadCast)或多播包(MutiCast)，执行泛洪<code>doFlood()</code>方法，其它类型数据包执行<code>doForwardFlow()</code>方法。<br>Forwarding类中对数据包的几种操作方法：</p>
<ul>
<li><code>doForwardFlow()</code>：转发</li>
<li><code>doFlood()</code>：泛洪</li>
<li><code>doDropFlow()</code>：丢包    </li>
</ul>
<p>接下来重点分析<code>doForwardFlow()</code>方法的实现流程。如图所示：<br><img src="/img/doforward.jpg" alt="doforward">    </p>
<p>doForwardFlow方法的工作流程：</p>
<ul>
<li>Step1：首先该方法会获取Packet_in消息中的数据包的匹配域，提取数据包中的交换机信息，依次判断源/目的交换机是否存在，是则继续执行，否则执行泛洪<code>doFlood()</code>；</li>
<li>Step2：当源、目的交换机均存在，接着会判断两者是否同属一个island(即同一个二层网络)，判断后的操作与前面步骤一样；</li>
<li>Step3：若同属一个island，然后会判断源目的交换机是否同一端口；</li>
<li>Step4：如果是在同一个island不同端口，便调取路径引擎(routingEngine)中的<code>getRoute()</code>方法获取源、目的交换机的路径，最后执行<code>pushRoute()</code>方法将路径下发到相应的交换机。</li>
</ul>
<p><strong>个人分析，欢迎指正，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Floodlight的流表下发模块是Forwarding类。处理Packet-in消息的方法是<code>processPacketInMessage()</code>，该方法根据决策(Decision)或者包的类型决定对Packet-in消息执行动作，对于广播包(Broa]]>
    </summary>
    
      <category term="Floodlight" scheme="http://liushy.com/tags/Floodlight/"/>
    
      <category term="Forwarding" scheme="http://liushy.com/tags/Forwarding/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解析Floodlight之TopologyInstance模块]]></title>
    <link href="http://liushy.com/2017/02/12/floodlight-topoins/"/>
    <id>http://liushy.com/2017/02/12/floodlight-topoins/</id>
    <published>2017-02-12T06:37:42.000Z</published>
    <updated>2017-02-12T08:20:46.000Z</updated>
    <content type="html"><![CDATA[<p>Floodlight的拓扑计算模块是TopologyInstance类，该类主要是生成拓扑信息以及计算两节点间路径，与TopologyManager在系统中是同属一个代码目录。主要分析拓扑计算模块类中的方法<code>compute()</code>：<br><img src="/img/topoins.jpg" alt="topoins"><br><code>compute()</code>运行的大致流程：</p>
<ul>
<li>Step1：调用方法<code>identifyOpenflowDomains()</code>通过<em>深度优先</em>的算法计算出整个网络中的所有集群clusters，每一个集群都是一个强相连的子图；</li>
<li>Step2：调用方法<code>addLinksToOpenflowDomains()</code>遍历所有的链路links，如果链路两端的交换机属于同一个集群cluster，则将该链路添加到这个集群中；</li>
<li>Step3：调用<code>calculateShortestPathTreeInClusters()</code>方法计算路径，该方法首先会清空路径缓存变量pathcache，再调用负载均衡路由算法计算每个cluster所有点之间的路径；</li>
<li>Step4：调用<code>calculateBroadcastNodePortsInClusters()</code>根据路径结果生成每个集群中的广播树结构，主要是为了避免环路产生广播风暴。控制器收到交换机上送的ARP包后，会先根据广播树决定ARP包应该被flood还是转发。     </li>
</ul>
<p>TopologyInstance类在计算路径时采用<strong><em>Dijkstra</em></strong>算法，基于跳数，即每条链路Cost值为1。除此之外，还定义了<code>buildroute()</code>方法和<code>getroute()</code>方法，<code>buildroute()</code>方法根据<code>compute()</code>计算的结果创建路径，<code>getroute()</code>方法则将<code>buildroute()</code>的路径缓存到<strong><em>pathcache</em></strong>中供转发模块Forwarding获取。   </p>
<p><strong>个人分析，欢迎指正，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Floodlight的拓扑计算模块是TopologyInstance类，该类主要是生成拓扑信息以及计算两节点间路径，与TopologyManager在系统中是同属一个代码目录。主要分析拓扑计算模块类中的方法<code>compute()</code>：<br><img sr]]>
    </summary>
    
      <category term="Floodlight" scheme="http://liushy.com/tags/Floodlight/"/>
    
      <category term="TopologyInstance" scheme="http://liushy.com/tags/TopologyInstance/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解析Floodlight之TopologyManager模块]]></title>
    <link href="http://liushy.com/2017/02/12/floodlight-topomanager/"/>
    <id>http://liushy.com/2017/02/12/floodlight-topomanager/</id>
    <published>2017-02-12T04:12:04.000Z</published>
    <updated>2017-02-12T08:24:49.000Z</updated>
    <content type="html"><![CDATA[<p>Floodlight的拓扑管理模块主要由TopologyManager 类来实现。TopologyManager监听LinkDiscoverManager的更新信息，一旦有链路更新了，就会实例化拓扑计算模块TopologyInstance，并运行函数<code>compute()</code>重新计算路径，并为转发模块Forwarding提供路径转发服务。模块启动后会间隔500ms运行一次线程<code>UpdateTopologyWorker</code>：<br><img src="/img/topoman.jpg" alt="topoman"><br><code>UpdateTopologyWorker</code>线程中只运行了一个方法<code>updateTopology()</code>，该方法大致的流程：</p>
<ul>
<li>Step1：首先调用<code>applyUpdates()</code>方法获取拓扑更新，如果链路有更新如新增链路就执行<code>addOrUpdateLink()</code>，如果链路down掉了，就执行删除<code>removeLink()</code>；</li>
<li>Step2：然后调用<code>createNewInstance()</code>方法创建一个TopologyInstance实例，并运行方法<code>compute()</code>计算路径；</li>
<li>Step3：<code>lastUpdateTime</code>用于记录上一次更新的时间，<code>informListeners()</code>向所有需要监听拓扑信息的模块传递拓扑更新信息</li>
</ul>
<p><strong>个人分析，欢迎指正，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Floodlight的拓扑管理模块主要由TopologyManager 类来实现。TopologyManager监听LinkDiscoverManager的更新信息，一旦有链路更新了，就会实例化拓扑计算模块TopologyInstance，并运行函数<code>comput]]>
    </summary>
    
      <category term="Floodlight" scheme="http://liushy.com/tags/Floodlight/"/>
    
      <category term="TopologyManager" scheme="http://liushy.com/tags/TopologyManager/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[解析Floodlight之LinkDiscoveryManager模块]]></title>
    <link href="http://liushy.com/2017/02/12/floodlight-linkdiscovermanager/"/>
    <id>http://liushy.com/2017/02/12/floodlight-linkdiscovermanager/</id>
    <published>2017-02-12T03:01:59.000Z</published>
    <updated>2017-02-12T08:20:46.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>Floodlight作为一款比较成熟的SDN控制器，前期是备受瞩目的，可由于版本更新太慢，且在2014-2015年间又蹿红了新的竞争者如Opendaylight,Onos等控制器，使得Floodlight风光大不如前，不过这主要是企业对Floodlight的态度，而对于更关注SDN架构本身的高校研究者来说，Floodlight相比Opendaylight和Onos更加轻量易读，不需折腾太繁琐的环境和依赖，更有助于对算法的研究。最近几个月，总有小伙伴询问Floodlight的相关问题。说实话，好久没碰了，能记得的内容我会很快解答，有些忘了的还得花时间翻翻代码。去年的毕业论文，我写了对Floodlight 架构的理解。所以我打算将部分内容整理一下（主要是模块的工作流程），写出来以供参考或者备忘。本文即是Floodlight中链路发现模块的解析，如有不正之处，一定提出哈。  </p>
<h2 id="LinkDiscoverManager">LinkDiscoverManager</h2>
<p>Floodlight中链路发现功能的实现类是LinkDiscoveryManager模块。该模块的主要工作是：向交换机下发LLDP包和BDDP包以及处理交换机上传的LLDP包和BDDP包，以此来记录全网的链路信息，即每条链路的源/目的交换机MAC地址、源/目的端口号等。   </p>
<p>其中，LLDP（Link Layer Discovery Protocol，链路发现协议）包，是一种二层数据包，该数据包标识了交换机的信息，邻居节点间相互广播LLDP来获取对方的存在，并将设备信息保存；BDDP包是BigSwitch公司定义的一种类似LLDP的数据包，BDDP包可以通过不受控制器管理的设备，用以发现一些不是直连的节点组合。比如两交换机中间有设备不受本控制器管理，由于LLDP是由控制器主动下发给交换机，所以这种情况下LLDP包是无法通过中间设备到达两交换机的，而这时控制器通过下发BDDP包通过中间设备来发现两交换机的连接关系。所以LLDP包和BDDP包的区别是前者可以发现直连的设备后者发现间接连接的设备。   </p>
<h2 id="解析LinkDiscoverManager多线程">解析LinkDiscoverManager多线程</h2>
<p>LinkDiscovermanager模块初始化后会启动三个线程，如图所示：<br><img src="/img/linkdiscovermanager.jpg" alt="linkdiscover"><br>图中所示的链路发现模块启动后的处理流程，涉及到三个线程和一个主要方法：</p>
<ul>
<li>线程<code>discoveryTask</code>主要实现发送LLDP包的任务，每隔1秒运行方法<code>discoverLinks()</code>，<code>discoverLinks()</code>方法中指定了一个计时方法<code>timeoutLinks()</code>，首先会处理掉那些过时了的链路links，其次，每间隔15秒要求全部交换机在所有端口发送LLDP包即运行方法<code>discoverOnAllPorts()</code>；</li>
<li>线程<code>bddpTask</code>主要实现发送BDDP包的任务，遍历所有已经发送 LLDP 包的端口, 如果该端口还没有建立过连接, 就发送 BDDP 包；</li>
<li>线程<code>updatesThread</code>主要负责更新消息回调，如果有链路或者端口发生变化，则处理这些更新并发布链路更新消息；</li>
<li>方法<code>handlePacketIn（）</code>主要处理交换机上传的Packet-in消息,解析LLDP包。</li>
</ul>
<p><strong>个人分析，欢迎指正，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2>
<p>Floodlight作为一款比较成熟的SDN控制器，前期是备受瞩目的，可由于版本更新太慢，且在2014-2015年间又蹿红了新的竞争者如Opendaylight,Onos等控制器，使得Floodlight风光大不如前，不过这主要是企业]]>
    </summary>
    
      <category term="Floodlight" scheme="http://liushy.com/tags/Floodlight/"/>
    
      <category term="LinkDiscoveryManager" scheme="http://liushy.com/tags/LinkDiscoveryManager/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[贰零幺陆]]></title>
    <link href="http://liushy.com/2016/12/24/goon-2016/"/>
    <id>http://liushy.com/2016/12/24/goon-2016/</id>
    <published>2016-12-24T13:45:06.000Z</published>
    <updated>2016-12-31T10:53:30.000Z</updated>
    <content type="html"><![CDATA[<p><img src="/img/jiuzai.JPG" alt="caoyuan">    </p>
<blockquote>
<p>图：<em>九寨沟的雪山 </em>    </p>
<p>2016眼看就要过去了，感觉思绪还是飘忽在年初和夏天那段时间。  </p>
<p>一年里，经历了论文，答辩，毕业，跨省，入职，身体和大脑至今是分离的。    </p>
<p>有时候早上半醒状态，会不自觉地想起昨晚让熊捡了漏，简直丢人。    </p>
<p>可是一睁眼却又发现，</p>
<p>我正睡在某间出租屋内，身处南京，我在这里上班，      </p>
<p>每天7:30起床，赶着坐8点过几分的班车。   </p>
</blockquote>
<h3 id="搞论文">搞论文</h3>
<p>2016和2015很多事情是连贯的，年初的论文就是15年留下的遗产，这个东西是真的磋磨人。去年的这个时候，我是报着一种就这样吧，开年了再管它的心态。所以，16年的前半年都在愁论文。雪上加霜的是，学院施行新政策，搞的人心惶惶的，各种恐怖的传言四起。幸好起初那段时间，我远离了重灾区，独自待在宿舍里写，有时候听回来的室友讲一些当前形势，也是各种心酸和惶恐。那时候整个通信学院笼罩在一种不安的氛围中，不知道谁就被延期毕业了。    </p>
<p>当然也不是每天都惆怅。有点儿时间，实验室几个哥们就约着搞点娱乐活动，切磋一下麻将，讲道理，这玩意能流行上千年不无道理。更主要的是大家在一块玩玩，互相调侃下，排解苦闷的心情。为了保证论文格式以及字体完全正确，交论文的前一晚，很多人都待在实验室里通宵改论文，还相互换着改，现在想起来还有点激动。最后上传了盲审的论文，整个人就简直虚脱了。   </p>
<h3 id="九寨沟">九寨沟</h3>
<p>交了论文，稍微有了些许空闲。我们三五个临时起意，就约着报了旅行团，去了一趟九寨沟。坑爹的是，为了赶第二天凌晨的大巴，还在两路口住了一夜。比较可惜的是，我们是四月底前往的，这时候正是九寨沟的枯水季，所以，看到的景色不是九寨最美丽的时候。不过，依然还是有不少游客哈。 </p>
<p><img src="/img/jiuzaiyouke.JPG" alt="jiuzai">     </p>
<h3 id="毕业答辩">毕业答辩</h3>
<p>回来后差不多一个月就答辩了。过程就不表了，问题很扯，直接问我为什么要做这个了，整个偏应用型，理论深度不够。当时我在讲台上还想狡辩来着，幸好有个重大的老师替我说了几句话，估计会下不来台。然后侥幸地通过了，宣布结果那一刻，有点懵。但走出教室后，心里各种滋味，心想老子再也不搞论文了。回想三年前，自己踌躇满志，一心搞学术，还计划着毕业后进个事业单位，舒服到终老。那时候想想都爽，嘿嘿。可事实是，我还是比较庸俗地投入到搞开发的队伍中去了。而实际上，时间花了也没搞出什么成绩来。     </p>
<p>细数自己这三年里，心态各种变化。到头来，发觉自己真的没有花太多时间专注在一件事情上，当然毕业论文是个例外，毕竟关乎生死。有时候我也在想，怎么才能让自己足够专注，也会突然想通了，然后花一两天时间做个小项目，可还是无法做到持之以恒。未来会怎么面对工作和生活，目前没有明确的方向，但只要是对的喜欢的，我就会去做。   </p>
<h3 id="云阳">云阳</h3>
<p>拍毕业照的那天，距离领毕业证还有几周的时间。所以拍完了照片，实验室的小伙伴们就决定一块儿去云阳玩，云阳是重庆下属的一个县城，印象最深的就是云阳的玻璃桥和栈道了。可是，由于我比较恐高，没敢去走，只能眼巴巴的看他们玩。更凄凉的是，不走栈道的话，我就要独自一人穿越山间的小树林。山路上一个人都没有，终于找到组织了，是碰到了同行的广州老太太，她指着不远处的山说，靓仔，你朋友在那里拍照呢。我没敢说恐高，冲她一笑。  </p>
<p><img src="/img/yunyang.JPG" alt="yunyang">   </p>
<p>然后就是毕业了。免不了俗，是真的舍不得这帮同学室友。想想大家都是天南海北聚拢，然后又各奔东西。有些人估计以后碰面的机会都没了，只能存在硬盘里了。当初签工作约时，我还毅然决然地选择了南京，现在都怀疑自己的脑回路，在当时是不是出现了故障，而我大多同学都留在了川渝或者回家乡的城市。与我同在重庆读研的松仔选择了广州，这下好了，朋友同学都不在身边了，离家人更远了，真的要自己一个人了。    </p>
<h3 id="南京">南京</h3>
<p>渡过了无聊的六月份，七月中就去单位报道了。初来南京，印象不是很好。那几天的雾霾很严重，天空昏暗，天气还燥热。网上刷租房广告，找中介看房源。与我同行的哥们是去年夏天参加公司活动认识的。还有几个是本校同学，目前大家都在公司的南京研究所。搞定了住宿问题，然后就是一系列的事情如体检，入职培训，认识同事等。刚走上岗位，还是挺有激情的，好多东西简直学不完。部门给了我们这些新人很多尝试的机会，说实话，在学校里接触的项目实在有限，公司提供的有些资源是在学校里无法接触到的。    </p>
<p>在南京这座城市待了快半年了，逛过的地方并不多。玄武湖还是蛮大的，湖边种了大片荷花，还挺壮观的，让我想起了我们那个小县城的公园—绿茵园，不知道现在是什么样子了。旁边不远处就是紫金山，周末爬爬山还可以。然后就是夫子庙，秦淮河，总统府….。大家应该都有感受，国内的城市景点大多一样，不是卖烤串，就是卖纪念品。。。人还多，各种味道飘在空中。还是非常怀念南山以及夜晚的洪崖洞。   </p>
<p><img src="/img/xuanwuhu.JPG" alt="xuanwuhu">    </p>
<h3 id="上海">上海</h3>
<p>中秋的时候，和云鹏去了趟上海。哈，一点不好玩，这座城市是足够繁华的，但真的没什么可以逛的，除了看各种楼就是逛逛黄浦江。但我还是比较中意上海的老民居，多是些中老年人在居住，几个人坐在小弄里悠闲地打麻将，这生活还是惬意的。上海待了两天，头天夜里下暴雨，全身湿透了，鞋子进了水，最后索性蹚着水回到了酒店。外滩的人是真的多，很多警察在管制交通，本来欣赏黄浦江的兴致也就变成了观赏汹涌的人流了。</p>
<p><img src="/img/shanghai.JPG" alt="shanghai">  </p>
<h3 id="春运">春运</h3>
<p>国庆回了一趟家，这也是今年唯一的一次回家了。现在离得远了，买个票都成难题。前两天抢春运的票，八点放票，几分钟就被洗劫了。像我这种没有经验的人，简直无法理解这种疯狂的。多谢同事帮我抢了张回重庆的票，让我感受到在祖国还是能生存的。然后我自己搞了个抢票APP，加了几十块钱，终于还是抢到了。现在连黄牛都合法了，还冠冕堂皇的做成了APP。对于这些抢票工具和软件，不知道是应该庆幸还是悲哀。   </p>
<p>一六年发生的大事小事也就这些吧，其实回过头来看，都不算什么。这一年我的生活没有一成不变，反而变动还很多，就像开头讲的，至今我的大脑还与身体分离的。有开心也有不爽，生活的常态，本就不是事事都朝你所想象发展的，当时感慨一番就行了，也没必要深究，生活还得继续不是？2016年就这么过去了，来年会怎么样，谁也不知道，但愿能保持初心，坚强地活着。    </p>
<p><img src="/img/wukong1.jpg" alt="wukong1">   </p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="/img/jiuzai.JPG" alt="caoyuan">    </p>
<blockquote>
<p>图：<em>九寨沟的雪山 </em>    </p>
<p>2016眼看就要过去了，感觉思绪还是飘忽在年初和夏天那段时间。  </p>
<p>]]>
    </summary>
    
      <category term="生活，旅游" scheme="http://liushy.com/tags/%E7%94%9F%E6%B4%BB%EF%BC%8C%E6%97%85%E6%B8%B8/"/>
    
      <category term="Life" scheme="http://liushy.com/categories/Life/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用docker部署hadoop分布式集群]]></title>
    <link href="http://liushy.com/2016/12/21/docker+hadoop/"/>
    <id>http://liushy.com/2016/12/21/docker+hadoop/</id>
    <published>2016-12-21T13:41:34.000Z</published>
    <updated>2017-03-04T12:12:14.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言_"><strong>前言 </strong></h2>
<p>这个部署是去年做的，有点久了，镜像上传在<a href="https://hub.docker.com/r/liushy/ubuntu/tags/" target="_blank" rel="external">dockerhub</a>，想了想，还是写下来，万一哪天有用，可以回顾一下。关于docker的一些内容，后序会写一些，碍于目前生产环境的限制，能做的不会太多，但更多的是熟练docker。hadoop呢，以前读书的时候，断断续续地研究过一段时间，然后就没然后了，事情太多太杂，而自身精力涣散，三天打鱼两天晒网，实际也就没弄明白什么。平时读点博客，看到docker，hadoop等字眼就会不住高潮，内心想说这玩意我玩过啊，然后也就仅限于此了。术业有专攻，如果不是经常接触，搞不久就会忘，若时常回顾一下，等到用时，就不会那么陌生了。   </p>
<h2 id="安装docker"><strong>安装docker</strong></h2>
<p>安装docker的套路网上有教程，目前新的Ubuntu系统都有集成，不过<a href="https://www.oschina.net/translate/installing-docker-on-mac-os-x" target="_blank" rel="external">OSX系统跑docker</a>需要配合虚拟机如Virtualbox等来做，所以mac用户要稍微折腾一下了。本文的环境是在Ubuntu 14下做的，大致命令如下：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">sudo</span> apt-get install apt-transport-https </div><div class="line">$ <span class="built_in">sudo</span> apt-key adv --keyserver hkp://keyserver.ubuntu.com:<span class="number">80</span> --recv-keys <span class="number">36</span>A1D7869245C8950F966E92D8576A8BA88D21E9 </div><div class="line">$ <span class="built_in">sudo</span> bash -c <span class="string">"echo deb https://get.docker.io/ubuntu docker main &gt; /etc/apt/sources.list.d/docker.list"</span> </div><div class="line">$ <span class="built_in">sudo</span> apt-get update </div><div class="line">$ <span class="built_in">sudo</span> apt-get install lxc-docker</div></pre></td></tr></table></figure>


<p>docker的安装可以参考<a href="http://www.cnblogs.com/xiaoluosun/p/5520510.html" target="_blank" rel="external">这个</a>   </p>
<p>接下来要提到的是docker仓库的概念，熟悉github或使用过svn的都应该知道代码库吧，而我们也可以为docker创建仓库，这个库即是存放docker镜像的场所。比如我们做了个装有JDK的docker镜像，那么就可以将其存到仓库里，每次需要使用带Java的环境时，就可以可以使用该镜像，并在此基础上构建其它镜像。国内比较知名的docker库如<a href="https://github.com/DockerPool/" target="_blank" rel="external">dockerpool</a>，而我此次使用的是<a href="https://hub.docker.com/" target="_blank" rel="external">dockerhub</a>，国内访问剧慢，最好使用vpn加速。建议养成使用仓库的习惯，无论是代码还是docker。怎么使用docker仓库呢，首先需要在dockerhub官网创建一个账户，创建自己的仓库，然后在你的生产环境登陆<a href="https://hub.docker.com/" target="_blank" rel="external">dockerhub</a>，即可从<a href="https://hub.docker.com/" target="_blank" rel="external">dockerhub</a>上pull（拉取）镜像，当然也可以将本地的镜像push（上传）到仓库。大致流程可<a href="http://geek.csdn.net/news/detail/35121" target="_blank" rel="external">参考此文</a>。  </p>
<p>登录到DockerHub：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ docker login --username=账户 --email=邮箱@xxx.com</div><div class="line">PassWord:</div><div class="line">WARNING: login credentials saved <span class="keyword">in</span> /home/hadoop/.docker/config.json</div><div class="line">Login Succeeded</div></pre></td></tr></table></figure>

<p>搞定仓库设置后，那么就可以从docker仓库中获取Ubuntu镜像了：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull ubuntu:<span class="number">14.04</span></div></pre></td></tr></table></figure>

<p>使用<code>docker images</code>可以查看本地的所有镜像：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hadoop@hadoop:~$ docker images</div><div class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</div><div class="line">liushy/ubuntu       hadoop              <span class="number">358</span>d6e31872e        <span class="number">13</span> months ago       <span class="number">1.276</span> GB</div><div class="line">liushy/ubuntu       java                <span class="number">50</span>d62690f3f0        <span class="number">13</span> months ago       <span class="number">752.9</span> MB</div><div class="line">ubuntu              <span class="number">14.04</span>               e9ae3c220b23        <span class="number">13</span> months ago       <span class="number">187.9</span> MB</div></pre></td></tr></table></figure>


<p>显示的内容包括：   </p>
<ul>
<li>REPOSITORY：仓库名，例如liushy/ubuntu和ubuntu</li>
<li>TAG：标记,例如hadoop</li>
<li>IMAGE ID：镜像ID号，这是唯一的</li>
<li>CREATED：创建时间</li>
<li>SIZE：镜像大小   </li>
</ul>
<p>那么，除此之外，还需要了解docker的一些常用操作。   </p>
<h2 id="启动Docker容器_"><strong>启动Docker容器 </strong></h2>
<p>启动docker容器，就可以构建部署hadoop集群了。使用如下命令启动docker容器：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -ti ubuntu</div></pre></td></tr></table></figure>

<p>docker run -ti ubuntu命令中没有指定执行程序，Docker默认执行/bin/bash。如下面这条命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop@hadoop:~$  docker run liushy/ubuntu:java /bin/<span class="built_in">echo</span> <span class="string">'Hello world'</span></div><div class="line">Hello world</div></pre></td></tr></table></figure>


<p>即是启动标记为java的镜像，运行bash打印“Hello world”。<br>接下来我们在Ubuntu基础镜像的上，安装Java，执行如下命令：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">50</span>d62690f3f0:~<span class="comment">#sudo apt-get install software-properties-common python-software-properties</span></div><div class="line">root@<span class="number">50</span>d62690f3f0:~<span class="comment">#sudo add-apt-repository ppa:webupd8team/java</span></div><div class="line">root@<span class="number">50</span>d62690f3f0:~<span class="comment">#sudo apt-get update</span></div><div class="line">root@<span class="number">50</span>d62690f3f0:~<span class="comment">#sudo apt-get install oracle-java7-installer</span></div></pre></td></tr></table></figure>


<p>安装结束后，可以将该镜像保存，以备以后使用：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">50</span>d62690f3f0:~<span class="comment"># exit</span></div><div class="line">docker commit -m <span class="string">"java image"</span> <span class="number">50</span>d62690f3f0  liushy/ubuntu:java</div></pre></td></tr></table></figure>


<p><code>-m</code>后面指定提交说明，<code>50d62690f3f0</code>是容器ID（也可以通过<code>docker ps</code>查询运行的容器），<code>liushy/ubuntu</code>是仓库，<code>:java</code>是标记。</p>
<h2 id="构建Hadoop镜像"><strong>构建Hadoop镜像</strong></h2>
<p>首先启动Java容器的镜像，下载Hadoop，输入如下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">hadoop@hadoop:~$ docker run -ti liushy/ubuntu:java</div><div class="line">root@<span class="number">7</span>cf73e2147ec:/<span class="comment"># </span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:<span class="built_in">cd</span> ~</div><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># mkdir soft</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># cd soft/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft<span class="comment"># mkdir apache</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft<span class="comment"># cd apache/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache<span class="comment"># mkdir hadoop</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache<span class="comment"># cd hadoop/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop<span class="comment"># wget http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop<span class="comment"># tar xvzf hadoop-2.6.0.tar.gz</span></div></pre></td></tr></table></figure>


<p>本次安装的是hdoop-2.6.0版的   </p>
<h3 id="配置环境">配置环境</h3>
<p>还需要配置环境变量，在~/.bashrc添加java和hadoop文件路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">7</span>cf73e2147ec:vi ~/.bashrc</div><div class="line"><span class="keyword">export</span> JAVA_HOME=/usr/lib/jvm/java-<span class="number">7</span>-oracle</div><div class="line"><span class="keyword">export</span> HADOOP_HOME=/root/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span></div><div class="line"><span class="keyword">export</span> HADOOP_CONFIG_HOME=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</div><div class="line"><span class="keyword">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</div><div class="line"><span class="keyword">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</div></pre></td></tr></table></figure>


<p>最后，一定记得要<code>source ~/.bashrc</code>使配置生效。</p>
<h3 id="配置Hadoop">配置Hadoop</h3>
<p>部署分布式的hadoop，主要分为两大角色：Master和Slave。从HDFS的角度，由若干个NameNode和DataNode组成（在分布式文件系统中，NameNode管理文件系统的命名空间，DataNode管理存储的数据）；从MapReduce的角度，将主机划分JobTracker 和TaskTracker(主节点的Job分配多个Task给从节点执行)。HDFS在集群上实现分布式文件系统，MapReduce在集群上实现了分布式计算和任务处理。HDFS在MapReduce任务处理过程中提供了文件操作和存储等支持，MapReduce在HDFS的基础上实现了任务的分发、跟踪、执行等工作，并收集结果，二者相互作用，完成了Hadoop分布式集群的主要任务<a href="http://blog.chinaunix.net/uid-25266990-id-3900239.html" target="_blank" rel="external">[参考]</a>。   </p>
<p>部署hadoop的各个节点，需要修改hadoop的配置文件，包括core-site.xml、hdfs-site.xml、mapred-site.xml这三个文件。在此之前，建议新建如下目录:</p>
<ul>
<li>tmp：作为Hadoop的临时目录</li>
<li>namenode：作为NameNode的存放目录</li>
<li>datanode：作为DataNode的存放目录</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># cd $HADOOP_HOME/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># mkdir tmp</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># cd tmp/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/tmp<span class="comment"># cd ../</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># mkdir namenode</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># cd namenode/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/namenode<span class="comment"># cd ../</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># mkdir datanode</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span><span class="comment"># cd datanode/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec::~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/datanode<span class="comment"># cd $HADOOP_CONFIG_HOME/</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/hadoop<span class="comment"># cp mapred-site.xml.template mapred-site.xml</span></div></pre></td></tr></table></figure>


<p>接下来就是对上述几个文件进行配置：     </p>
<p><strong>core-site.xml配置：</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">value</span>&gt;</span>/root/soft/apache/hadoop/hadoop-2.6.0/tmp<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="title">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">final</span>&gt;</span>true<span class="tag">&lt;/<span class="title">final</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="title">description</span>&gt;</span>xxxxxx.<span class="tag">&lt;/<span class="title">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></div></pre></td></tr></table></figure>


<ul>
<li>hadoop.tmp.dir：配置为/root/soft/apache/hadoop/hadoop-2.6.0/tmp为此前创建的临时目录。</li>
<li>fs.default.name：配置为hdfs://master:9000，指向Master节点  </li>
</ul>
<p><strong>hdfs-site.xml配置：</strong></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>2<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">final</span>&gt;</span>true<span class="tag">&lt;/<span class="title">final</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">description</span>&gt;</span>xxxxx.<span class="tag">&lt;/<span class="title">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>/root/soft/apache/hadoop/hadoop-2.6.0/namenode<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">final</span>&gt;</span>true<span class="tag">&lt;/<span class="title">final</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>/root/soft/apache/hadoop/hadoop-2.6.0/datanode<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">final</span>&gt;</span>true<span class="tag">&lt;/<span class="title">final</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></div></pre></td></tr></table></figure>


<ul>
<li>dfs.replication：配置为2。指集群为一个Master节点和两个Slave节点。</li>
<li>dfs.namenode.name.dir：配置为此前创建的NameNode目录</li>
<li>dfs.datanode.data.dir：配置为此前创建的NaDataNode目录   </li>
</ul>
<p><strong>mapred-site.xml配置：</strong>   </p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="title">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="title">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>master:9001<span class="tag">&lt;/<span class="title">value</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="title">description</span>&gt;</span>xxxxxx.<span class="tag">&lt;/<span class="title">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="title">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></div></pre></td></tr></table></figure>


<ul>
<li>mapred.job.tracker：配置jobTracker在master节点。 </li>
</ul>
<p>除此之外，还要配置conf/hadoop-env.sh文件,修改为你的jdk的安装位置:   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">export</span> JAVA_HOME=/usr/lib/jvm/java-<span class="number">7</span>-oracle</div></pre></td></tr></table></figure>


<p>还要格式化Namenode:<code>hadoop namenode -format</code></p>
<h3 id="节点SSH互访">节点SSH互访</h3>
<p>Hadoop启动以后，Namenode是通过SSH来启动和停止各个Datanode上的守护进程的，要求在节点之间执行指令的时候是不需要输入密码，故我们要配置SSH运用无密码公钥认证的形式。   </p>
<p>首先，安装SSH   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># sudo apt-get install ssh</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># ssh localhost</span></div></pre></td></tr></table></figure>

<p>利用<code>ssh localhost</code>测试一下是否设置好无口令登陆，如果没有设置好，系统将要求你输入密码，通过下面的设置可以实现无口令登陆：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa</span></div><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></div></pre></td></tr></table></figure>


<p>最后，保存一份镜像:   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@<span class="number">7</span>cf73e2147ec:~<span class="comment"># exit</span></div><div class="line">hadoop@hadoop:~$ docker commit -m <span class="string">"hadoop image"</span> <span class="number">358</span>d6e31872e liushy/ubuntu:hadoop</div></pre></td></tr></table></figure>

<h2 id="启动Hadoop集群"><strong>启动Hadoop集群</strong></h2>
<p>接下来就是启动hadoop集群了，本次部署的hadoop方案是，一个Master节点，两个Slave节点： 　　</p>
<font color="blue" size="4">#部署方案:</font>    

<table>
<thead>
<tr>
<th style="text-align:center">节点</th>
<th style="text-align:center">IP</th>
<th style="text-align:center">Hadoop任务</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Master</td>
<td style="text-align:center">172.17.0.2</td>
<td style="text-align:center">Namenode,jobTracker</td>
</tr>
<tr>
<td style="text-align:center">Slave1</td>
<td style="text-align:center">172.17.0.3</td>
<td style="text-align:center">Datanode,taskTracker</td>
</tr>
<tr>
<td style="text-align:center">Slave2</td>
<td style="text-align:center">172.17.0.4</td>
<td style="text-align:center">Datanode,taskTracker</td>
</tr>
</tbody>
</table>
<p>启动容器使用如下命令：   </p>
<ul>
<li><code>docker run -ti -h master liushy/ubuntu:hadoop</code>   </li>
<li><code>docker run -ti -h slave1 liushy/ubuntu:hadoop</code>    </li>
<li><code>docker run -ti -h slave2 liushy/ubuntu:hadoop</code>    </li>
</ul>
<p>其中，<code>-h</code>指定的是容器的主机名，比如<code>master slave1 slave2</code><br>容器启动成功后，docker会为它们自动分配ip地址，是同一网段相互之间能够ping通，在容器中输入<code>ifconfig</code>查看。当然也可以修改ip，方法请自行百度。   </p>
<h3 id="修改hosts">修改hosts</h3>
<p>接下来修改各节点的hosts文件<code>vi /etc/hosts</code>，添加各节点的hostname和ip：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="number">172.17</span>.<span class="number">0.2</span>        master</div><div class="line"><span class="number">172.17</span>.<span class="number">0.3</span>        slave1</div><div class="line"><span class="number">172.17</span>.<span class="number">0.4</span>        slave2</div></pre></td></tr></table></figure>


<h3 id="修改slaves">修改slaves</h3>
<p>除此之外，还要在master节点上，配置slaves文件，该文件需要填写slave节点的hostname:   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@master:~<span class="comment"># cd $HADOOP_CONFIG_HOME/</span></div><div class="line">root@master:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/hadoop<span class="comment"># vi slaves</span></div><div class="line">slave1</div><div class="line">slave2</div></pre></td></tr></table></figure>


<h3 id="启动Hadoop">启动Hadoop</h3>
<p>在Master节点的hadoop目录下执行<code>start-all.sh</code>，启动Hadoop集群:   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">root@master:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/hadoop<span class="comment"># start-all.sh </span></div><div class="line">This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh</div><div class="line">starting secondarynamenode, logging to /root/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/logs/hadoop-root-secondarynamenode-master.out</div><div class="line">starting yarn daemons</div><div class="line">...</div><div class="line"><span class="number">0.0</span>.<span class="number">0.0</span>:starting resourcemanager, logging to /root/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/logs/yarn--resourcemanager-master.out</div><div class="line">slave2: starting nodemanager, logging to /root/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/logs/yarn-root-nodemanager-slave2.out</div><div class="line">slave1: starting nodemanager, logging to /root/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/logs/yarn-root-nodemanager-slave1.out</div></pre></td></tr></table></figure>

<p>打印上述日志，说明集群运行成功，碍于生产环境，运行较慢，可以多等等。使用jps命令可以查看各节点运行的进程。 </p>
<p><strong>master节点：</strong>    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">root@master:~/soft/apache/hadoop/hadoop-<span class="number">2.6</span>.<span class="number">0</span>/etc/hadoop<span class="comment"># jps</span></div><div class="line"><span class="number">492</span> Jps</div><div class="line"><span class="number">429</span> ResourceManager</div><div class="line"><span class="number">295</span> SecondaryNameNode</div><div class="line"><span class="number">124</span> NameNode</div></pre></td></tr></table></figure>



<p><strong>slave1节点：</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@slave1:/<span class="comment"># jps</span></div><div class="line"><span class="number">52</span> DataNode</div><div class="line"><span class="number">147</span> NodeManager</div><div class="line"><span class="number">240</span> Jps</div></pre></td></tr></table></figure>



<p><strong>slave2节点：</strong>   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">root@slave2:/<span class="comment"># jps</span></div><div class="line"><span class="number">50</span> DataNode</div><div class="line"><span class="number">121</span> NodeManager</div><div class="line"><span class="number">250</span> Jps</div></pre></td></tr></table></figure>


<p>通过web访问hadoop运行情况：<br><img src="/img/docker-hadoop.png" alt="hadoop-web"><br>针对hadoop的架构和操作此文就不深入阐述了。</p>
<h2 id="结语"><strong>结语</strong></h2>
<p>搭建环境是一件费时耗力，低效率的事情，搞不好就各种排错，甚至重来，这也是很多人不想接触环境的原因。如何做到少出错，快速定位问题，我想这也是很多正在搞环境的开发人员所渴望的一种工作状态。其实，没有什么捷径可走，还是要多积累，但有些事情必须得长期坚持，那就是学习操作系统，内存管理，网络等相关知识。很多疑难杂症多因环境变量的配置，硬盘故障，网络不通等引起，而我们往往因为对这些知识不熟悉，而手足无措。    </p>
<p>回到本文的主题，docker是这两年势头正旺的开源产品，基于lxc（linux container），使得应用部署更加轻量。如何将其运用于开发环境中，很多互联网公司都在做。作为开发人员来说，掌握容器也是一门专业利器，基于容器结合应用可以实现大规模的业务部署，比如本文的hadoop。当然相比虚拟机，docker也有缺陷，比如隔离性差，所以如何运用docker来保障处理业务的安全稳定，是开发人员需要通过实践来解决的问题。   </p>
<p><strong>参考网站</strong><br><a href="http://blog.chinaunix.net/uid-25266990-id-3900239.html" target="_blank" rel="external">http://blog.chinaunix.net/uid-25266990-id-3900239.html</a><br><a href="http://blog.csdn.net/u011692203/article/details/46898293" target="_blank" rel="external">http://blog.csdn.net/u011692203/article/details/46898293</a><br><a href="http://www.cnblogs.com/xiaoluosun/p/5520510.html" target="_blank" rel="external">http://www.cnblogs.com/xiaoluosun/p/5520510.html</a><br><a href="http://tashan10.com/yong-dockerda-jian-hadoopwei-fen-bu-shi-ji-qun/#" target="_blank" rel="external">http://tashan10.com/yong-dockerda-jian-hadoopwei-fen-bu-shi-ji-qun/</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言_"><strong>前言 </strong></h2>
<p>这个部署是去年做的，有点久了，镜像上传在<a href="https://hub.docker.com/r/liushy/ubuntu/tags/" target="_blank" rel="ex]]>
    </summary>
    
      <category term="docker" scheme="http://liushy.com/tags/docker/"/>
    
      <category term="Hadoop" scheme="http://liushy.com/tags/Hadoop/"/>
    
      <category term="Linux" scheme="http://liushy.com/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Linux内存占用]]></title>
    <link href="http://liushy.com/2016/11/27/Linux-mem/"/>
    <id>http://liushy.com/2016/11/27/Linux-mem/</id>
    <published>2016-11-27T02:39:51.000Z</published>
    <updated>2016-11-27T03:39:56.000Z</updated>
    <content type="html"><![CDATA[<p>记录一下几个常用的查看Linux内存和硬盘的命令，以备查看使用：   </p>
<h3 id="top">top</h3>
<p>top命令是Linux下常用的性能分析工具，能够实时显示系统中进程的资源占用状况，类似于Windows的任务管理器可以直接使用top命令后，查看%MEM的内容。可以指定进程或者用户查看，如查看oracle用户的进程内存使用情况的话可以使用如下的命令：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ top -u oracle</div></pre></td></tr></table></figure>

<p>显示内容解释：</p>
<blockquote>
<p>PID：进程的ID<br>USER：进程所有者<br>PR：进程的优先级别，越小越优先被执行<br>NInice：值<br>VIRT：进程占用的虚拟内存<br>RES：进程占用的物理内存<br>SHR：进程使用的共享内存<br>S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数<br>%CPU：进程占用CPU的使用率<br>%MEM：进程使用的物理内存和总内存的百分比<br>TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。<br>COMMAND：进程启动命令名称   </p>
</blockquote>
<p>常用的命令：</p>
<blockquote>
<p>P：按%CPU使用率排行<br>T：按MITE+排行<br>M：按%MEM排行   </p>
</blockquote>
<h3 id="pmap">pmap</h3>
<p>可以根据进程查看进程相关信息占用的内存情况，(进程号可以通过ps查看)如下所示：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ pmap <span class="operator">-d</span> <span class="number">14596</span></div></pre></td></tr></table></figure>


<h3 id="ps">ps</h3>
<p>ps 的参数众多, 在此仅列出几个常用的参数：   </p>
<blockquote>
<p>-A 列出所有的行程<br>-w 显示加宽可以显示较多的资讯<br>-au 显示较详细的资讯<br>-aux 显示所有包含其他使用者的行程   </p>
</blockquote>
<p>au(x) 输出格式 :<br>USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND   </p>
<blockquote>
<p>USER: 行程拥有者<br>PID: pid<br>%CPU: 占用的 CPU 使用率<br>%MEM: 占用的记忆体使用率<br>VSZ: 占用的虚拟记忆体大小<br>RSS: 占用的记忆体大小<br>TTY: 终端的次要装置号码 (minor device number of tty)<br>STAT: 该行程的状态:<br>D: 不可中断的静止<br>R: 正在执行中<br>S: 静止状态<br>T: 暂停执行<br>Z: 不存在但暂时无法消除<br>W: 没有足够的记忆体分页可分配<br>&lt;: 高优先序的行程<br>N: 低优先序的行程<br>L: 有记忆体分页分配并锁在记忆体内<br>START: 行程开始时间<br>TIME: 执行的时间<br>COMMAND:所执行的指令   </p>
</blockquote>
<h3 id="du">du</h3>
<p>du命令主要是用来查看硬盘使用情况的：  </p>
<blockquote>
<p>  du -sh : 查看当前目录总共占的容量。而不单独列出各子项占用的容量<br>du -lh —max-depth=1 : 查看当前目录下一级子文件和子目录占用的磁盘容量。   </p>
</blockquote>
<h3 id="free">free</h3>
<p>free是最常用的查看内存占用的命令，有以下参数：   </p>
<blockquote>
<p>-b：以Byte为单位显示内存使用情况；<br> -k：以KB为单位显示内存使用情况；<br>-m：以MB为单位显示内存使用情况；<br>-o：不显示缓冲区调节列；<br>-s&lt;间隔秒数&gt;：持续观察内存使用状况；<br>-t：显示内存总和列；<br>-V：显示版本信息。<br>举例说明：  </p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">free -m </div><div class="line">            total  used  free shared  buffers cached </div><div class="line">Mem:        <span class="number">2016</span>   <span class="number">1973</span>  <span class="number">42</span>     <span class="number">0</span>     <span class="number">163</span>    <span class="number">1497</span> </div><div class="line">-/+ buffers/cache: <span class="number">312</span>   <span class="number">1703</span> </div><div class="line">Swap:       <span class="number">4094</span>    <span class="number">0</span>    <span class="number">4094</span></div></pre></td></tr></table></figure>


<p>输出的第一行：   </p>
<blockquote>
<p>total：内存总数；<br>used：已经使用的内存数；<br>free：空闲的内存数；<br>shared：当前已经废弃不用；<br>buffers Buffer：缓存内存数；<br>cached Page：缓存内存数。   </p>
</blockquote>
<p>第二行（-/+ buffers/cache）：   </p>
<blockquote>
<p>(-buffers/cache) used内存数：第一行Mem行中的 used – buffers – cached<br>(+buffers/cache) free内存数: 第一行Mem行中的 free + buffers + cached   </p>
</blockquote>
<p>第三行是交换区的使用情况，那么什么时候会用到交换区的内存呢，即当可用内存少于额定值的时候，就会进行交换。可以通过<code>cat /proc/meminfo</code>来查看内存额定值：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">hadoop@hadoop:~$ cat /proc/meminfo </div><div class="line">MemTotal:        <span class="number">1017576</span> kB</div><div class="line">MemFree:          <span class="number">206012</span> kB</div><div class="line">MemAvailable:     <span class="number">479832</span> kB</div><div class="line">Buffers:           <span class="number">47344</span> kB</div><div class="line">Cached:           <span class="number">333836</span> kB</div><div class="line">SwapCached:            <span class="number">0</span> kB</div><div class="line">Active:           <span class="number">455128</span> kB</div><div class="line">Inactive:         <span class="number">271084</span> kB</div><div class="line">Active(anon):     <span class="number">345856</span> kB</div><div class="line">Inactive(anon):     <span class="number">4140</span> kB</div><div class="line">Active(file):     <span class="number">109272</span> kB</div><div class="line">Inactive(file):   <span class="number">266944</span> kB</div><div class="line">Unevictable:          <span class="number">32</span> kB</div><div class="line">Mlocked:              <span class="number">32</span> kB</div><div class="line">SwapTotal:       <span class="number">1047548</span> kB</div><div class="line">SwapFree:        <span class="number">1047548</span> kB</div><div class="line">Dirty:               <span class="number">588</span> kB</div><div class="line">Writeback:             <span class="number">0</span> kB</div><div class="line">AnonPages:        <span class="number">345060</span> kB</div><div class="line">Mapped:           <span class="number">174264</span> kB</div><div class="line">Shmem:              <span class="number">4968</span> kB</div><div class="line">Slab:              <span class="number">38328</span> kB</div><div class="line">SReclaimable:      <span class="number">20452</span> kB</div><div class="line">SUnreclaim:        <span class="number">17876</span> kB</div><div class="line">KernelStack:        <span class="number">5312</span> kB</div><div class="line">PageTables:        <span class="number">23708</span> kB</div><div class="line">NFS_Unstable:          <span class="number">0</span> kB</div><div class="line">Bounce:                <span class="number">0</span> kB</div><div class="line">WritebackTmp:          <span class="number">0</span> kB</div><div class="line">CommitLimit:     <span class="number">1556336</span> kB</div><div class="line">Committed_AS:    <span class="number">2404256</span> kB</div><div class="line">VmallocTotal:   <span class="number">34359738367</span> kB</div><div class="line">VmallocUsed:       <span class="number">23324</span> kB</div><div class="line">VmallocChunk:   <span class="number">34359709832</span> kB</div><div class="line">HardwareCorrupted:     <span class="number">0</span> kB</div><div class="line">AnonHugePages:     <span class="number">65536</span> kB</div><div class="line">HugePages_Total:       <span class="number">0</span></div><div class="line">HugePages_Free:        <span class="number">0</span></div><div class="line">HugePages_Rsvd:        <span class="number">0</span></div><div class="line">HugePages_Surp:        <span class="number">0</span></div><div class="line">Hugepagesize:       <span class="number">2048</span> kB</div></pre></td></tr></table></figure>

]]></content>
    <summary type="html">
    <![CDATA[<p>记录一下几个常用的查看Linux内存和硬盘的命令，以备查看使用：   </p>
<h3 id="top">top</h3>
<p>top命令是Linux下常用的性能分析工具，能够实时显示系统中进程的资源占用状况，类似于Windows的任务管理器可以直接使用top命令后，查看]]>
    </summary>
    
      <category term="内存" scheme="http://liushy.com/tags/%E5%86%85%E5%AD%98/"/>
    
      <category term="Linux" scheme="http://liushy.com/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[OVS配置命令]]></title>
    <link href="http://liushy.com/2016/11/26/OVS-CLI/"/>
    <id>http://liushy.com/2016/11/26/OVS-CLI/</id>
    <published>2016-11-26T10:12:53.000Z</published>
    <updated>2016-11-26T12:23:29.000Z</updated>
    <content type="html"><![CDATA[<p>在ovs结构中，如果网络拓扑是vxlan或gre，则有两个bridge，分别是br-int和br-tun，br-int叫集成网桥，用于连接起上方的各个设备（包括vm、dhcp-agent、l3-agent），br-tun叫隧道网桥，隧道既可以是gre，也可以是vxlan，br-tun负责在原始报文中加入gre或vxlan报文头。相当于软件实现了vtep设备(对于vxlan而言)<br>以下是本人使用和收集的OVS相关配置命令：       </p>
<p>建立 VXLAN Network ID (VNI) 和指定的 OpenFlow port number, eg: VNI=5566, OF_PORT=9   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> interface vxlan <span class="built_in">type</span>=vxlan option:remote_ip=x.x.x.x option:key=<span class="number">5566</span> ofport_request=<span class="number">9</span></div></pre></td></tr></table></figure>



<p>VNI flow by flow</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> interface vxlan <span class="built_in">type</span>=vxlan option:remote_ip=<span class="number">140.113</span>.<span class="number">215.200</span> option:key=flow ofport_request=<span class="number">9</span></div></pre></td></tr></table></figure>



<p>设置 VXLAN tunnel id   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ovs-ofctl add-flow ovs-br <span class="keyword">in</span>_port=<span class="number">1</span>,actions=<span class="keyword">set</span>_field:<span class="number">5566</span>-&gt;tun_id,output:<span class="number">2</span></div><div class="line">ovs-ofctl add-flow s1 <span class="keyword">in</span>_port=<span class="number">2</span>,tun_id=<span class="number">5566</span>,actions=output:<span class="number">1</span></div></pre></td></tr></table></figure>



<p>查询out-of-band $ in-band   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl get controller ovs-br connection-mode</div></pre></td></tr></table></figure>



<p>Out-of-band   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> controller ovs-br connection-mode=out-of-band</div></pre></td></tr></table></figure>



<p>In-band (default)   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> controller ovs-br connection-mode=<span class="keyword">in</span>-band</div></pre></td></tr></table></figure>


<p>移除 hidden flow   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> bridge br0 other-config:disable-in-band=<span class="literal">true</span></div></pre></td></tr></table></figure>


<p>设置 GRE tunnel   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs−vsctl add−port ovs-br ovs-gre -- <span class="keyword">set</span> interface ovs-gre <span class="built_in">type</span>=gre options:remote_ip=<span class="number">1.2</span>.<span class="number">3.4</span></div></pre></td></tr></table></figure>


<p>设置 Vlan trunk   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl add-port ovs-br eth0 trunk=<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span></div></pre></td></tr></table></figure>


<p>设置已 add 的 port 为 access port, vlan id 9</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ovs-vsctl <span class="keyword">set</span> port eth0 tag=<span class="number">9</span></div></pre></td></tr></table></figure>


<p>网络工程是一门大学问，虽然本科四年里偶有涉及，硕士阶段专攻了一年多的路由交换原理，到目前开始从事网络安全开发工作，我也不敢说自己精通网络，深知自身仍然还有很多要学的地方，而对于网络知识的学习，我觉得最好的方式莫过于搞一套网络设备来慢慢折腾，模拟一个个应用场景，敲一下各种配置命令，能够一步步照着做了，想弄明白网络就不是难事，总的来说，急不得，在了解理论的基础上，动手实践理解会更深刻，还有一点就是多做记录，正所谓好记性不如烂笔头，我推荐做一个自己的博客或者使用笔记软件，记录自己平时的实践和理论学习。<br>参考网站：<br><a href="http://blog.csdn.net/beginning1126/article/details/41172365" title=" http://blog.csdn.net/beginning1126/article/details/41172365" target="_blank" rel="external"> http://blog.csdn.net/beginning1126/article/details/41172365</a><br><a href="http://blog.csdn.net/tantexian/article/details/46707175" title="http://blog.csdn.net/tantexian/article/details/46707175" target="_blank" rel="external">http://blog.csdn.net/tantexian/article/details/46707175</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在ovs结构中，如果网络拓扑是vxlan或gre，则有两个bridge，分别是br-int和br-tun，br-int叫集成网桥，用于连接起上方的各个设备（包括vm、dhcp-agent、l3-agent），br-tun叫隧道网桥，隧道既可以是gre，也可以是vxlan，b]]>
    </summary>
    
      <category term="OVS" scheme="http://liushy.com/tags/OVS/"/>
    
      <category term="VXLAN" scheme="http://liushy.com/tags/VXLAN/"/>
    
      <category term="GRE" scheme="http://liushy.com/tags/GRE/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[随便聊聊]]></title>
    <link href="http://liushy.com/2015/11/12/talk--life/"/>
    <id>http://liushy.com/2015/11/12/talk--life/</id>
    <published>2015-11-12T12:34:44.000Z</published>
    <updated>2016-11-26T10:43:48.000Z</updated>
    <content type="html"><![CDATA[<h2 id="唠唠">唠唠</h2>
<p>快到年终了，该来个年终总结什么的。。。咳咳。。好久没发文了，本博创建伊始主要是为了记录自己平时的技术心得，距离上次发表文章超过半年了，很恐怖啊，其实这段时间也看了不少文章，还是有不少感悟。细细想来还是自己太懒了，当然中途有部分时间在写自己的小论文，找工作balala，很累，以至于忘了搭理自己这个博客了。现在忙的事情都先告一段落了，还好，今天得空了，想了想，还是得对自己这几个月梳理梳理，由于本文与技术无关，所以新建了一个专题 [<em>Life</em>] 打算以后写不出技术文章的时候，就在这里说说自己的生活感悟。</p>
<h2 id="聊聊">聊聊</h2>
<p>其实这半年是真的很累，距离上一次发文不久，我就参加了全国的大学生SDN应用创新大赛，准备了一个多月，很无奈，没获奖，只得到了一个参赛证明，我们属于研究生组的。比较喜剧的是，本校有一个本科生参赛组在提交作品前，还请我们去给人家指导，结果人家最后进入了决赛，还拿了奖。。。汗。。。不得不说师弟们很厉害哈！师兄没起到带头作用，丢人了。。。<br>然后是上面提到的找工作，说实话，我觉得找工作这事儿特诡异，怎么说呢？面试ZX是一个很偶然的时候，当时ZX来重庆招蓝剑，说实话，蓝剑是什么东东，当时的我一概不知，所以也就没管，恰好这时，本实验室一哥们去面了，完了特兴奋地给我打电话喊我去面试。当时我还没反应过来怎么回事，还怀疑这哥们是不是受刺激了，然后和实验室另一基友去面了。。面试过程就不扒了，此处省略N个字。。。现在算半只脚踏进了zx里了，前段时间，部门来电话了，说是做SDN，主要方向是云安全的，这下好了，心里算踏实了，一直以来我都是比较关注云安全这一块的，然后还要结合SDN来做，哈哈，这不是为我量身打造的吗~心里挺满意的哈，不过也得自己有那个能力，以后嘛~~好好干涩！ 送上一张蓝剑夏令营，在深圳拍的<br><img src="/img/lanjian.JPG" alt="lanjian"></p>
<h2 id="玩玩">玩玩</h2>
<p>前段时间出去玩了，好久没这么嗨了，十月底出去的，同室友一起去了龚滩古镇，西昌和泸沽湖。玩的挺累的，不过景色好心情也好，还有好客的当地人，算是不错的一趟旅行。第一站来到了龚滩古镇，位于重庆与贵州的交界处——酉阳县，古镇依江而建，镇对面是拔地而起的万丈高崖，江面绿波荡漾，逛了一圈花了将近一下午的时间，很是羡慕当地人，面朝江面，４Ｍ带宽的生活，有些生活细节让我莫名的感动，看到有一家人坐在电视机前吃饭，小孩子一边扒饭一边盯着电视看动画片，爸妈都在桌前吃饭聊着什么，孩子他妈时不时提醒小朋友多吃点饭别老看电视，这个场景让我想起了小时候，内心忍不住有些感慨。当夜我们就住进了一处江边的客栈，超级便宜，每人４０元，热水ｗｉｆｉ电视该有的都有，晚上坐在江边的馆子里吃了些当地的特色，味道还行，略贵－——－！甩张图给你们看一下：   　　　</p>
<p><img src="/img/gongtan.JPG" alt="gongtan"><br>第二站来到了西昌，这个日照充足的地方很有意思，下了火车我还以为来到了西北一样，整个地区很平不像重庆山多，灰尘蛮大的，各种工程车行驶而过。人生地不熟的，没瞎逛我们就直奔传说中的琼海了，琼海其实就是一个大湖，但时不时来点浪哈，一股咸盐味。海边修的公园，不远处是一块湿地，当天逛完了琼海我们就租了自行车在湿地里逛了一圈，路面很宽干净，在加上西昌的阳光，非常不错的骑行。晚上吃了西昌当地的特色——醉虾，活虾就那么放在一堆作料里闷，吃在嘴里还在跳，怪怪的。甩一张琼海的<br><img src="/img/xichang.JPG" alt="qionghai"><br>第三站我们来到了美丽的女儿国——泸沽湖，第一次认识泸沽湖，是在[转山]这本书里，网上搜索了泸沽湖，顿时被图片里的她惊艳了，一直想去，但被各种原因搁浅了。这个湖太大了，连接了四川和云南两省，绕湖一圈七十多公里，而且还分了四川泸沽湖和云南泸沽湖。下车我们就先去了草海，这地方是泸沽湖旁的一块湿地，据说以前走婚的时候，男方就是划着船儿过草海来到摩梭人家的，晚上去次日早上回，当地人为了安全，每家每户出钱出力修了一条走婚桥。草海真是纯净无污染，收图<br><img src="/img/caohai.JPG" alt="caohai"><br>第一天夜里住在了里格的一家青年旅社，真心便宜，这边的客栈房间里几乎都提供了电热毯，所以晚上睡着不会太冷。第二天早上天没亮就出门了，哈哈，看日出。船家将我们送到一个视野最好的湖滩上等日出，日出难得啊，可是冷啊～雾好大啊～但还好，等到了<br><img src="/img/richu.JPG" alt="richu"><br>最后一天就是绕湖观光，走得很累，但景色确实不错，纯净自然，阳光充足，比雾都重庆好太多，感觉自己就是来这洗肺的，看看这纯净的湖面<br><img src="/img/luguhu.JPG" alt="luguhu">　　　</p>
<h2 id="哈哈">哈哈</h2>
<p>最后以此标题做个总结吧，这一年就这样结束了，没什么大事儿，感觉就是这么细水长流般渡过了，玩也玩了，该完成的项目也完成了。这一年收获蛮大的，事实上相比一年前，懂得东西更多了，更深入了，还有了一定的成果，可喜可贺，工作定了还算比较顺利，结识了一些搞技术的朋友，知识面更开阔了，也发现了自身诸多的不足。开心的是出去旅行一圈的愿望实现了，特别是去了我梦里的女儿国哈！新年伊始还有很多事要做，毕业论文什么的，为上班做好准备等等～好好干吧，孩子！新年快乐，么么哒～</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="唠唠">唠唠</h2>
<p>快到年终了，该来个年终总结什么的。。。咳咳。。好久没发文了，本博创建伊始主要是为了记录自己平时的技术心得，距离上次发表文章超过半年了，很恐怖啊，其实这段时间也看了不少文章，还是有不少感悟。细细想来还是自己太懒了，当然中途有部分时间在写]]>
    </summary>
    
      <category term="生活，旅游" scheme="http://liushy.com/tags/%E7%94%9F%E6%B4%BB%EF%BC%8C%E6%97%85%E6%B8%B8/"/>
    
      <category term="Life" scheme="http://liushy.com/categories/Life/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Floodlight中模块对Packet_in报文的处理]]></title>
    <link href="http://liushy.com/2015/04/07/Floodlight-packetin/"/>
    <id>http://liushy.com/2015/04/07/Floodlight-packetin/</id>
    <published>2015-04-07T14:03:26.000Z</published>
    <updated>2016-11-26T14:12:57.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>看源码最痛苦的是知其然而不知其所以然，当然也有人建议我不要在意这些细节~~，可是看不懂浑身不舒服啊亲，我也希望自己有高超的写代码能力，事实是还需努力。接触Floodlight这么久了，以前做的最多的是调用RET API进行一些实验，改过官方为开发者提供的MACTracker代码，但实际上没花太多时间看源码，最近做实验啥的感觉瓶颈了，唉，遂决心好好研究一下源码，看是否能给自己新的灵感。此次参考的源码是我修改过的MACTracker，我将要分析的是其中对Packet_in事件处理的方法recevie（）   </p>
<h2 id="Packet_in处理分析">Packet_in处理分析</h2>
<p>首先，贴上代码，主要功能是获取连上控制器的主机的MAC地址，IP地址并在控制台显示出来。   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> net.floodlightcontroller.core.IListener.Command <span class="title">receive</span>(IOFSwitch sw, OFMessage msg, FloodlightContext cntx) {</div><div class="line">Ethernet eth = IFloodlightProviderService.bcStore.get(cntx,IFloodlightProviderService.CONTEXT_PI_PAYLOAD);</div><div class="line">Long sourceMACHash = Ethernet.toLong(eth.getSourceMACAddress());</div><div class="line"><span class="keyword">if</span>(eth.getPayload() <span class="keyword">instanceof</span> IPv4){</div><div class="line">  IPv4 pkt = (IPv4)eth.getPayload().clone();</div><div class="line">  String src = IPv4.fromIPv4Address(pkt.getSourceAddress());</div><div class="line">  String dst = IPv4.fromIPv4Address(pkt.getDestinationAddress());</div><div class="line">  <span class="keyword">if</span> (!macAddresses.contains(sourceMACHash)) {</div><div class="line">	 macAddresses.add(sourceMACHash);</div><div class="line">	 logger.info(<span class="string">"MAC Address: {} IP Address: {} seen on switch"</span>,HexString.toHexString(sourceMACHash),src);</div><div class="line">      }</div><div class="line">  }</div><div class="line"><span class="keyword">return</span> Command.CONTINUE;</div><div class="line">}</div></pre></td></tr></table></figure>


<h3 id="Packet_in包处理流程">Packet_in包处理流程</h3>
<p>1.receive()是模块用来处理Packt_in数据包的函数，每个需要处理Packet_in包的模块均默认以它命名，所以它们获取OpenFlow消息的方式也是相同的。<br>2.首先通过代码：   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Ethernet eth = IFloodlightProviderService.bcStore.get(cntx, IFloodlightProviderService.CONTEXT_PI_PAYLOAD)</div></pre></td></tr></table></figure>


<p>获取消息。其中通过调用接口IFloodlightProviderService的静态方法bcstore获取OpenFlow消息，而该消息是一个Ethernet对象。我们可以通过Ethernet里的方法getSourceMACaddress()获取该报文的源MAC地址；然后再通过getPayload()获取报文的有效载荷(所谓有效载荷，指的是除去协议头部之外实际传输的数据)，根据有效载荷可以判断报文的协议类型：ARP,IPv4,ICMP,DUCP等网络层协议类型。<br>3.若是IPv4包：IPv4类里有个方法getSourceAddress()获取源IP地址(二进制)，通过方法fromIPv4Address将IP地址转换为点分十进制的。   </p>
<h3 id="bcstore">bcstore</h3>
<p>bcstore是接口IFloodlightProvider里定义的一个对象，主要是存储OpenFlow消息，消息的对象是Ethernet类型的。bcstore本身是FloodightContextStore&lt;&gt;类型的，该类型有个方法用来获取存储的消息：get(FloodlightContext bc,String key).方法具体实现如下：   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> V <span class="title">get</span>(FloodlightContext bc, String key) {</div><div class="line">        <span class="keyword">return</span> (V)bc.storage.get(key);}</div></pre></td></tr></table></figure>


<h3 id="return-Command-CONTINUE">return.Command.CONTINUE</h3>
<p>最开始照着开发者文档做的时候，看到recieve()结尾处的return.Command.CONTINUE的解释是“该方法返回Command.CONTINUE以便其他处理程序继续处理”，而且我查看了其他好几个模块recieve函数返回值都是Command.CONTINUE，于是就找到了Command的源头。原来Command是接口<em>Ilistener</em>下的一个枚举类型：   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">enum</span> Command {</div><div class="line">        CONTINUE, STOP</div><div class="line">    }</div></pre></td></tr></table></figure>


<p>当时我就纳闷了，返回一个枚举类型值，谁来处理它？怎么处理这个值以实现能让其他模块继续执行的功能？于是我挨个模块源码寻找,终于在模块<code>net.floodlight.core.internal.controller</code>找到了它的身影：   </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">pktinProcTime.recordStartTimePktIn();</div><div class="line">Command cmd;</div><div class="line"><span class="keyword">for</span> (IOFMessageListener listener : listeners) {</div><div class="line">     pktinProcTime.recordStartTimeComp(listener);</div><div class="line">     cmd = listener.receive(sw, m, bc);</div><div class="line">     pktinProcTime.recordEndTimeComp(listener);</div><div class="line">     <span class="keyword">if</span> (Command.STOP.equals(cmd)) {</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">     }</div><div class="line">}</div></pre></td></tr></table></figure>


<p>这段代码就是对recevie()返回值进行处理，如果返回的是STOP，则该事件停止处理，也就是当前模块处理完后其他模块就没法处理了，而默认情况下事件会被每个模块遍历处理，所以我们会看到大多处理事件的模块返回的值都是CONTINUE。   </p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2>
<p>看源码最痛苦的是知其然而不知其所以然，当然也有人建议我不要在意这些细节~~，可是看不懂浑身不舒服啊亲，我也希望自己有高超的写代码能力，事实是还需努力。接触Floodlight这么久了，以前做的最多的是调用RET API进行一些实验，改]]>
    </summary>
    
      <category term="Floodlight" scheme="http://liushy.com/tags/Floodlight/"/>
    
      <category term="Packet_in" scheme="http://liushy.com/tags/Packet-in/"/>
    
      <category term="recevie" scheme="http://liushy.com/tags/recevie/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[基于floodlight&sflow的队列调整]]></title>
    <link href="http://liushy.com/2015/02/02/sflow-queue/"/>
    <id>http://liushy.com/2015/02/02/sflow-queue/</id>
    <published>2015-02-02T12:16:13.000Z</published>
    <updated>2016-11-26T10:48:10.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>介绍本次实验前，我想先讲讲关于流量监控的事。嗯，<a href="http://liushy.com/2015/01/27/sflow-ddos/" target="_blank" rel="external">基于sflow的ddos防御</a> 的成功，坚定了我继续基于sflow做流量监控。对于流量监控，我最初的想法是通过openflow协议的count和meter入手。不幸的是，通过count能统计端口数据包和字节数，难以实现速率的监控；meter可以对端口进行速率控制，但<a href="https://github.com/openvswitch/ovs/blob/master/FAQ.md#q-does-open-vswitch-support-openflow-meters" target="_blank" rel="external">OVS FAQ</a>有提到OVS2.0以后都支持了meter,可是还没有实现meter的功能。回到主题，这一次的实验是基于sflow监控的基础上，通过floodlight进行的队列调整。   </p>
<h2 id="实验设计">实验设计</h2>
<p>1.拓扑结构沿用上次实验的：switch+3hosts+floodlight+sflow如图：<br>　　<img src="/img/ddos-topo.png" alt="queue-topo"><br>2.设计思想：switch上有三个端口分别连接有host1,host2,host3。在端口3上设置3条队列，分别带宽设置为：<br>— —id=@q0 create queue other-config:min-rate=1000000000 other-config:max-rate=1000000000<br>— —id=@q1 create queue other-config:max-rate=20000000 other-config:min-rate=20000000<br>— —id=@q2 create queue other-config:max-rate=2000000 other-config:min-rate=2000000<br>让host1和host2同时向host3发包通过流量监控，获取端口1和端口2的速率分别为R1和R2，然后进行判断：<br>　　若R1&gt;R2:端口1到端口3的队列—&gt;q0    端口2到端口3的队列—&gt;q2<br>　　若R2&gt;R1:端口1到端口3的队列—&gt;q2    端口2到端口3的队列—&gt;q0<br>　　若R1=R2:端口1到端口3的队列—&gt;q1    端口2到端口3的队列—&gt;q1    </p>
<h2 id="结果分析">结果分析</h2>
<p>首先让host1和host2分别向host3泛洪：<br>　　h1&gt; ping -f h3<br>　　h2&gt; ping -f h3<br>执行队列调整应用后终端显示:<br>　　<img src="/img/console-view.png" alt="console"><br>可以看出，由于端口1(注意：eth0~eth2依次对应端口1~3)的速率比端口2的速率快，应用立即通知控制器下发流表给端口1和端口2设定不同的出口队列，再来看看控制器的流表：<br>　　<img src="/img/queue-flows.png" alt="queue-flow"><br>从流表可以看到，控制器已经下发了队列调整流表项。端口1的速率变化：<br>　　<img src="/img/s1-eth0-rate.png" alt="eth0-rate"><br>端口2的速率变化：<br>　　<img src="/img/s1-eth1-rate.png" alt="eth1-rate"><br>从图中我们可以看到，最初阶段，端口1和端口2的速率均在2M左右；从时间17:13:18开始，也就是实施队列调整应用后，端口1的速率上升到了大于2M阶段，而端口2的速率下降到了500k以下。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2>
<p>介绍本次实验前，我想先讲讲关于流量监控的事。嗯，<a href="http://liushy.com/2015/01/27/sflow-ddos/" target="_blank" rel="external">基于sflow的ddo]]>
    </summary>
    
      <category term="sflow" scheme="http://liushy.com/tags/sflow/"/>
    
      <category term="floodlight" scheme="http://liushy.com/tags/floodlight/"/>
    
      <category term="queue" scheme="http://liushy.com/tags/queue/"/>
    
      <category term="qos" scheme="http://liushy.com/tags/qos/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[sflow流量监控之ddos防御]]></title>
    <link href="http://liushy.com/2015/01/27/sflow-ddos/"/>
    <id>http://liushy.com/2015/01/27/sflow-ddos/</id>
    <published>2015-01-27T08:17:47.000Z</published>
    <updated>2016-12-01T14:06:35.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言">前言</h2>
<p>最近做的一个实验，需要获取链路接口的实时信息，比如带宽，流量统计等等。起初，我打算从openflow协议中的计数器入手，openflow交换机对每一个流维护一个计数器，控制器可以从这些计数器上查询每条链路的实时流量信息。随着网络规模增大，流量增加时，对计数器管理会变得越来越消耗系统资源，如<a href="http://www.openflowhub.org/display/floodlightcontroller/FAQ+Floodlight+OpenFlow+Controller" title="Floodlight FAQ" target="_blank" rel="external">Floodlight FAQ</a>所提到对控制器而言这样的监控很难准确的，所以就否定了在控制器上实现流量监控的想法，转而考虑通过第三方平台监控每条链路的实时流量信息。sflow可以提供周期性的网络接口统计采样和数据包采样，能够提供各接口的流量信息，且几乎不会对被统计设备造成任何负担，管理成本极低。sflow的部署分为两部分：sflow agent和sflow collector。sflow agent内嵌入网络设备中获取设备的实时信息并封装成sflow报文发送给sflow collector。sflow collector汇总后得出统计数据。初次使用sflow监控流量，做了一个ddos防御的实验。   </p>
<h2 id="实验环境">实验环境</h2>
<p>本次实验是在一台物理主机上完成实验拓扑，控制器部署和sflow部署。通过mininet模拟一个switch，三台host。控制器使用Floodlight。由于mininet已经部署了sflow agent，所以只需要部署sflow collector。<br>实验拓扑如下图：<br><img src="/img/ddos-topo.png" alt="ddos-topo"><br>sflow官网推荐了几款sflow软件如sflow-trend,sflow-rt等，这里我选择的是sflow-rt，安装sflow-rt很简单。<br>1.首先，下载<a href="http://www.inmon.com/products/sFlow-RT.php" target="_blank" rel="external">官方压缩包</a><br>2.然后解压安装：    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$tar</span> -zxvf sflow.tar.gz   </div><div class="line"><span class="variable">$cd</span> sflow/sflow-rt   </div><div class="line">$./start.sh</div></pre></td></tr></table></figure>


<p>在ovs交换机上还要配置sflow agent，输入以下命令：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$sudo</span> ovs-vsctl -- --id=@sflow create sflow agent=eth0 target=\<span class="string">"192.168.2.233:6343\" header=128 sampling=10 polling=1 -- set bridge s1 sflow=@sflow</span></div></pre></td></tr></table></figure>


<p>注意：agent是要监听的网卡，这个网卡一定要能监听到我们所需的交换机的流量，target是sflow collector所在的ip地址，bridge设定需要监听的交换机。   </p>
<h2 id="实验原理">实验原理</h2>
<p>sflow-rt统计到的每个接口的流量信息，我们可以通过sflow-rt的rest api获取json数据并对json数据进行解析获得。对解析到的数据进行判断分析后即可实施策略。本次实验原理如下：<br>1.首先对sflow-rt进行配置，设定metric=ddos,并设定它的阈值，当监测到的流量超过这个阈值时即判断为ddos；<br><em>定义地址组</em>：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -H <span class="string">"Content-Type:application/json"</span> -X PUT --data <span class="string">"{external:['0.0.0.0/0'], internal:['10.0.0.0/8']}"</span> http://localhost:<span class="number">8008</span>/group/json</div></pre></td></tr></table></figure>


<p><em>定义流 </em>：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -H <span class="string">"Content-Type:application/json"</span> -X PUT --data <span class="string">"{keys:'ipsource,ipdestination', value:'frames', filter:'sourcegroup=external&destinationgroup=internal'}"</span> http://localhost:<span class="number">8008</span>/flow/incoming/json</div></pre></td></tr></table></figure>


<p><em>定义阈值</em>：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -H <span class="string">"Content-Type:application/json"</span> -X PUT --data <span class="string">"{metric:'ddos', value:1000}"</span> http://localhost:<span class="number">8008</span>/threshold/incoming/json</div></pre></td></tr></table></figure>

<p>2.若判断为ddos，即调用Floodlight的staticflowentrypusher对ddos攻击包进行丢弃；<br>由于sflow获取的的openflow信息是使用snmp中定义的ifindex对各接口进行标记，而openflow有它自己的标记方式，所以应该对openflow端口号和ifindex端口号进行映射。本次实验采用nodejs作为应用语言。    </p>
<h2 id="实验结果">实验结果</h2>
<p>本次实验ddos攻击采取host1向host2泛洪的方式。命令如下：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mininet&gt;h1 ping <span class="operator">-f</span> h2</div></pre></td></tr></table></figure>


<p>运行ddos防御应用前：<br><img src="/img/ddos泛洪.png" alt="ddos"><br>我们可以看到，未运行ddos防御应用时，h1向h2泛洪的数据包达到了大约每秒30k个包。<br>接下来运行ddos防御应用：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nodejs ddosm.js</div></pre></td></tr></table></figure>


<p>运行ddos防御应用后：<br><img src="/img/ddos截取.png" alt="ddos2"><br>可以看出，运行ddos防御应用后，h1向h2泛洪的包迅速被完全的丢弃了。   </p>
<h2 id="总结">总结</h2>
<p>写这篇文主要目的不是介绍怎么写应用，而是对sflow性能的一个展示。流量监控是sdn中很重要的一环，我们在获取各个接口的实时信息后，可以实现很多的服务，比如负载均衡，QOS，流量工程等。这也是我初次尝试sflow,还有很多不解的地方，我的想法是，做好sflow与控制器的交互，完善流量监控的功能，为以后的各种服务提供帮助。<br><strong>参考网站</strong>：<a href="http://blog.sflow.com/2013/05/controlling-large-flows-with-openflow.html" target="_blank" rel="external">sflow官博</a><br><strong>DDOS源码参考</strong>：<a href="https://github.com/shylou/floodlight-ddos" target="_blank" rel="external">DDOS源码</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言">前言</h2>
<p>最近做的一个实验，需要获取链路接口的实时信息，比如带宽，流量统计等等。起初，我打算从openflow协议中的计数器入手，openflow交换机对每一个流维护一个计数器，控制器可以从这些计数器上查询每条链路的实时流量信息。随着网络规模增]]>
    </summary>
    
      <category term="sflow" scheme="http://liushy.com/tags/sflow/"/>
    
      <category term="floodlight" scheme="http://liushy.com/tags/floodlight/"/>
    
      <category term="ddos" scheme="http://liushy.com/tags/ddos/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[SDN环境下两主机通信过程]]></title>
    <link href="http://liushy.com/2014/11/15/floodlight-twohosts-ping/"/>
    <id>http://liushy.com/2014/11/15/floodlight-twohosts-ping/</id>
    <published>2014-11-15T11:47:25.000Z</published>
    <updated>2016-11-26T10:45:30.000Z</updated>
    <content type="html"><![CDATA[<h2 id="感悟">感悟</h2>
<p>SDN看了也有两个月了吧，刚接触时很兴奋呐，感觉就是一控制器加一交换机呗。弄懂里面的函数结构，接下来搞编程应该就可以了吧~~可是这仅仅是我天真的想法。当别人问我为什么是这样的时候，放到最初那会儿，我会干脆的说：SDN就是这样啊；而现在，我会很小心地分析它的协议流程，害怕漏掉或者说错某个细节。越了解越敬畏，一个概念的产生并且盛行是经过许多学者推敲和认证的，所   以无论是做科研还是学术，我们都应有一个严谨的态度。</p>
<h2 id="两主机通信过程">两主机通信过程</h2>
<p>本次实验环境Floodlight+Mininet。我们利用mininet仿真出一个switch下三台hosts：h1,h2,    h3,然后h2 ping h3;通过wirshark抓包分析openflow的协议流程。（在本文我就不分析不同   switch下不同host的ping包过程了）默认加载了转发模块。拓扑图如下：<br><img src="/img/topo.png" alt="topo">     </p>
<p>1.最初h2会通过将自己和h3的ip地址同子网掩码与运算得知：自己和h3在同一网段，可直接通信；<br>2.h2对数据包二层封装时，发现自己并不知道h3的mac地址，于是发送ARP广播包；<br>3.switch收到arp广播包后，由于没有流表，于是它向控制器发送packet_in消息：<br>4.控制器收到packet_in后，向switch发送packet_out,并下发流表给switch让它将数据包从除2端口以外的其他所有端口发送；<br>5.h3收到arp数据包后，在数据包里添加上自己的mac地址；<br>6.switch收到h3的arp包，由于没有流表项，于是向控制器发送packet_in消息；<br>7.控制器学习到h3的mac和ip地址，向switch发送packet_out消息并下发h3到h2的流表项；<br>8.h2知道了h3的mac地址，完成icmp包的封装，就向h3发包了；<br>9.由于switch没有h2-&gt;h3的流表项，所以它还是会向控制器发送packet_in；<br>10.控制器发送packet_out给switch并下发h2-&gt;h3的流表；至此h2和h3就能不通过控制器只通过switch直接通信啦！<br>下面是寻址阶段抓包截图：（注：抓取的是通过eth0的包，eth0与控制器通信，所以也就是抓的控制器的包）<br><img src="/img/ping过程.png" alt="ping过程">     </p>
<p>寻址结束后，抓取控制器的包时，没有了h2 ping h3的icmp包,在端口2抓包：<br><img src="/img/s1-eth2.png" alt="端口2">   </p>
<p>在端口3抓包：<br><img src="/img/s1-eth3.png" alt="端口3">   </p>
<h2 id="Openflow与传统路由的比较">Openflow与传统路由的比较</h2>
<p>Openflow与传统路由一样，在源主机不知道目的主机mac地址的情况下，都会进行arp寻址。但不同之处在于，传统路由没有控制器，所有流表在switch里,转发和控制都由switch负责；而Openflow协议里，switch若没有匹配流表（或者没有流表），它会向控制器发送请求，让控制器下发策略。<br><strong>这是我个人的分析，欢迎指正，大家共同学习，若转载请注明出处！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="感悟">感悟</h2>
<p>SDN看了也有两个月了吧，刚接触时很兴奋呐，感觉就是一控制器加一交换机呗。弄懂里面的函数结构，接下来搞编程应该就可以了吧~~可是这仅仅是我天真的想法。当别人问我为什么是这样的时候，放到最初那会儿，我会干脆的说：SDN就是这样啊；而现在]]>
    </summary>
    
      <category term="floodlight" scheme="http://liushy.com/tags/floodlight/"/>
    
      <category term="ping" scheme="http://liushy.com/tags/ping/"/>
    
      <category term="openflow" scheme="http://liushy.com/tags/openflow/"/>
    
      <category term="SDN" scheme="http://liushy.com/categories/SDN/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[openwrt-example]]></title>
    <link href="http://liushy.com/2014/11/14/openwrt-example/"/>
    <id>http://liushy.com/2014/11/14/openwrt-example/</id>
    <published>2014-11-14T15:27:00.000Z</published>
    <updated>2016-12-25T02:07:08.000Z</updated>
    <content type="html"><![CDATA[<p>这里的开发环境是在Ubuntu下，搭建好OpenWrt的交叉编译环境，这里不多说了，网上有很多教程。本次示例选择的OpenWrt版本是trunk版.     </p>
<a id="more"></a>     

<p>接下来是添加模块具体步骤：<br>1.进入trunk的package文件夹，创建模块目录：<br>cd trunk/package<br>mkdir example<br>2.进入example目录，创建Mackefile文件和代码路径：<br>cd example<br>touch Mackefile<br>mkdir src<br>Makefile代码如下：  </p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">include</span> <span class="variable">$(</span><span class="constant">TOPDIR</span>)/rules.mk   </div><div class="line"><span class="keyword">include</span> <span class="variable">$(</span><span class="constant">INCLUDE_DIR</span>)/kernel.mk   </div><div class="line"><span class="constant">PKG_NAME</span><span class="symbol">:</span>=example</div><div class="line"><span class="constant">PKG_RELEASE</span><span class="symbol">:</span>=<span class="number">1</span></div><div class="line"><span class="keyword">include</span> <span class="variable">$(</span><span class="constant">INCLUDE_DIR</span>)/package.mk</div><div class="line">   </div><div class="line">define <span class="constant">KernelPackage</span>/example</div><div class="line">  <span class="constant">SUBMENU</span><span class="symbol">:</span>=<span class="constant">Other</span> modules</div><div class="line">  <span class="constant">TITLE</span><span class="symbol">:</span>=example driver</div><div class="line">  <span class="constant">DEPENDS</span><span class="symbol">:</span>=<span class="variable">@LINUX_2_6</span></div><div class="line">  <span class="constant">FILES</span><span class="symbol">:</span>=<span class="variable">$(</span><span class="constant">PKG_BUILD_DIR</span>)/*.<span class="variable">$(</span><span class="constant">LINUX_KMOD_SUFFIX</span>)</div><div class="line">  <span class="constant">KCONFIG</span><span class="symbol">:</span>=</div><div class="line">endef</div><div class="line">    </div><div class="line">define <span class="constant">KernelPackage</span>/example/description</div><div class="line">  <span class="constant">Kernel</span> <span class="class"><span class="keyword">module</span> <span class="title">to</span> <span class="title">example</span></span></div><div class="line">endef</div><div class="line">   </div><div class="line"><span class="constant">EXTRA_KCONFIG</span><span class="symbol">:</span>= \</div><div class="line">	<span class="constant">CONFIG_EXAMPLE</span>=m</div><div class="line"><span class="constant">EXTRA_CFLAGS</span><span class="symbol">:</span>= \</div><div class="line">	<span class="variable">$(</span>patsubst <span class="constant">CONFIG_</span>%, -<span class="constant">DCONFIG_</span>%=<span class="number">1</span>, <span class="variable">$(</span>patsubst %=m,%,<span class="variable">$(</span>filter %=m,<span class="variable">$(</span><span class="constant">EXTRA_KCONFIG</span>)))) \</div><div class="line">	<span class="variable">$(</span>patsubst <span class="constant">CONFIG_</span>%, -<span class="constant">DCONFIG_</span>%=<span class="number">1</span>, <span class="variable">$(</span>patsubst %=y,%,<span class="variable">$(</span>filter %=y,<span class="variable">$(</span><span class="constant">EXTRA_KCONFIG</span>)))) \</div><div class="line"><span class="constant">MAKE_OPTS</span><span class="symbol">:</span>= \</div><div class="line">	<span class="constant">ARCH</span>=<span class="string">"$(LINUX_KARCH)"</span> \</div><div class="line">	<span class="constant">CROSS_COMPILE</span>=<span class="string">"$(TARGET_CROSS)"</span> \</div><div class="line">	<span class="constant">SUBDIRS</span>=<span class="string">"$(PKG_BUILD_DIR)"</span> \</div><div class="line">	<span class="constant">EXTRA_CFLAGS</span>=<span class="string">"$(EXTRA_CFLAGS)"</span> \</div><div class="line">	<span class="variable">$(</span><span class="constant">EXTRA_KCONFIG</span>)</div><div class="line">   </div><div class="line">define <span class="constant">Build</span>/<span class="constant">Prepare</span></div><div class="line">	mkdir -p <span class="variable">$(</span><span class="constant">PKG_BUILD_DIR</span>)</div><div class="line">	<span class="variable">$(</span><span class="constant">CP</span>) ./src/* <span class="variable">$(</span><span class="constant">PKG_BUILD_DIR</span>)/</div><div class="line">endef</div><div class="line">       </div><div class="line">define <span class="constant">Build</span>/<span class="constant">Compile</span></div><div class="line">	<span class="variable">$(</span><span class="constant">MAKE</span>) -<span class="constant">C</span> <span class="string">"$(LINUX_DIR)"</span> \</div><div class="line">		<span class="variable">$(</span><span class="constant">MAKE_OPTS</span>) \</div><div class="line">		modules</div><div class="line">endef</div><div class="line"><span class="variable">$(</span>eval <span class="variable">$(</span>call <span class="constant">KernelPackage</span>,example))</div></pre></td></tr></table></figure>



<p>3.进入src目录，创建代码路径和相关源文件<br>cd src<br>touch example.c Kconfig Makefile<br>example.c代码：    </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;linux/init.h&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;linux/module.h&gt;</span></div><div class="line"><span class="preprocessor">#<span class="keyword">include</span> &lt;linux/kernel.h&gt;</span></div><div class="line"><span class="comment">/* hello_init ---- 初始化函数，当模块装载时被调用，如果成功装载返回0 否则返回非0值 */</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">int</span> __init hello_init(<span class="keyword">void</span>)</div><div class="line">{</div><div class="line">	printk(<span class="string">"I bear a charmed life.\n"</span>);</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">}</div><div class="line"><span class="comment">/* hello_exit ---- 退出函数，当模块卸载时被调用 */</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">void</span> __exit hello_exit(<span class="keyword">void</span>)</div><div class="line">{</div><div class="line">	printk(<span class="string">"Out, out, brief candle\n"</span>);</div><div class="line">}</div><div class="line">module_init(hello_init);</div><div class="line">module_exit(hello_exit);</div><div class="line">MODULE_LICENSE(<span class="string">"GPL"</span>);</div><div class="line">MODULE_AUTHOR(<span class="string">"liuxie"</span>);</div></pre></td></tr></table></figure>







]]></content>
    <summary type="html">
    <![CDATA[<p>这里的开发环境是在Ubuntu下，搭建好OpenWrt的交叉编译环境，这里不多说了，网上有很多教程。本次示例选择的OpenWrt版本是trunk版.     </p>
]]>
    
    </summary>
    
      <category term="OpenWrt" scheme="http://liushy.com/tags/OpenWrt/"/>
    
      <category term="Linux" scheme="http://liushy.com/categories/Linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hello World]]></title>
    <link href="http://liushy.com/2014/11/14/hello-world/"/>
    <id>http://liushy.com/2014/11/14/hello-world/</id>
    <published>2014-11-14T15:23:15.000Z</published>
    <updated>2014-11-14T08:07:18.000Z</updated>
    <content type="html"><![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="http://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">trobuleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick_Start">Quick Start</h2>
<h3 id="Create_a_new_post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run_server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate_static_files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy_to_remote_sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>

<p>More info: <a href="http://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Welcome to <a href="http://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="http://hexo.io]]>
    </summary>
    
  </entry>
  
</feed>
